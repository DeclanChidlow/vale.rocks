---
title: How I'm Using AI
description: An overview of my personal usage of Large Language Models (LLMs) and other generative AI. Tracking my experiences with AI tools, specific models (ChatGPT, Claude, Gemini, etc), applying them practically, and realistic perspective on their strengths and limitations over time, from coding attempts to language learning assistance.
og_description: As long as AI isn't using me...
pub_time: 2025-05-02
mod_time: 2025-12-31
section: Essay
tags: [AI, LLMs]
---

AI is a divisive technology, and it has a lot of flaws. I'm not an AI evangelist, but I don't think it is a useless technology. I think we need more people engaging in realistic conversations about the technology and about how they can, do, and don't use it. This post is me trying to be part of the change I'd like to see by writing realistically about how I use and approach AI, including what doesn't work.

I have an interest in the underlying technologies behind large language models such that I spend time understanding and studying how they work and how the field is progressing. This sets me up well to use them in an effective manner while minimising the negative impacts. I usually understand why they fail in the odd and specific ways they do as a result of understanding how they work, and this helps me work around and mitigate common failure modes.

I am not certain that people without this underlying interest in LLMs entirely benefit from using them. Even knowing some of the shortcomings on a surface level isn't quite enough to work around the problems intrinsic to the transformer architecture. I remain unconvinced that LLMs have a net positive impact for most people without an understanding of their core mechanics.

## Timeline

As AI is evolving, so is my usage of it. This is my attempt to keep a personal timeline of experimentation, usage, and adoption. The AI space is a fast-moving beast, and I think it interesting to keep tabs on how my usage changes. This post isn't entirely comprehensive but is fairly representative.

### Pre-2022

While not an AI, I had great fun playing with Siri in the early to mid-2010s. It was my first interaction with a conversational assistant, and I bullied her relentlessly, as young children do.

I played with Cleverbot during the later half of the 2010s. I mainly asked it naughty questions, to which I'd sometimes get vague responses. It was so very limited and only a brief novelty.

Google's [Quick Draw](https://quickdraw.withgoogle.com) was astonishing in that it could comprehend my scribbles with relative accuracy. I must have played with that surrounding the transition from the 2010s to the 2020s.

I was impressed by the realistic humans generated by [This Person Does Not Exist](https://thispersondoesnotexist.com) circa 2019. The faces were shockingly realistic, though details separate from the face, such as people in the background, were deformed, oddly gelatinous blob people.

### 2022

I referenced the output of GPT-3 via OpenAI's Playground prior to ChatGPT's release when writing assignments and spent a lot of time experimenting with the technology. I was conscious that GPT-3 was very limited in capabilities but that it was exciting and good for writing generic boilerplate.

I switched to using GPT-3.5 via ChatGPT shortly after its launch. Fairly capable, but still extremely flawed.

I gave [Craiyon](https://www.craiyon.com) a test, but its image output was a garbled mess and interesting only as a proof of concept.

### 2023

I experimented with DALLÂ·E 2 for generating concepts and inspiration. It gave me a vague source of inspiration for some specific concepts that hadn't been explored before but was overall extremely poor in quality and not particularly useful.

I created [Jarg](https://jarg.vale.rocks) at this time to interact and experiment with models not yet available in ChatGPT for free users, such as GPT-4, though I kept using ChatGPT as my primary interface.

My main usage throughout 2023 remained testing, experimenting, and extraordinarily menial tasks rather than actual usage, though I could see genuine applications of the technology beginning to form and approach viability. I did manage to find bona fide, applicable usage as a really good context-regarding thesaurus and rhyme machine.

### 2024

In 2024 I began seriously using LLMs for code generation, although under strict supervision. I wasn't confident enough to permit them to work unsupervised, but I was happy to use them for generating one-off, non-mission-critical tools or for doing menial but verifiable tasks such as [writing regular expressions](/micros/20250320-1225). They do well with languages such as BASH, JavaScript, PHP, and Python, but I find them exceedingly poor for HTML and CSS.

I tried briefly to use LLM editor integrations such as GitHub Copilot but disliked the user experience. I felt I lost granular control over their actions and that they were sloppy in pulling in useful context when attempting to solve problems -- which was the main benefit as far as I was concerned. I continued to use web interfaces and copy in any necessary code. I tried LLM line completions but found them slow and inferior to non-AI implementations.

Mid-year, I moved over to Anthropic's Claude 3.5 Sonnet. Like many others, I found its coding abilities incredibly impressive, though was disappointed by its [continuous bias towards more complex technologies](/posts/ai-is-stifling-tech-adoption#system-prompt-influence) when I just wanted it to use HTML/CSS/JS. I remained using ChatGPT as a fallback when I ran out of messages, thanks to its strict usage limitations.

I locally hosted several models, but my computer wasn't capable of running anything reasonable with any degree of speed.

I experimented with DeepSeek V3 and found it capable but inferior to Claude 3.5 Sonnet. I also really disliked the censorship.

I tested Perplexity and found it interesting but prone to hallucinations and therefore completely unfit for use as a general search engine. ChatGPT Search was equally poor as a general search engine, but I found utility in ChatGPT pulling in web content to avoid the limitations of its knowledge cutoff.

Late in the year I began using LLMs for help with my Japanese learning. Mainly for the purpose of quizzing me on words and phrases or to converse with me and offer corrections as necessary. Language is the bread and butter of a Large _Language_ Model, and it did a very good job. I used [DeepL](https://www.deepl.com/en/translator) on occasion to verify it wasn't just spouting rubbish, and it wasn't any of the times I verified.

### 2025

I switched to Claude 3.7 Sonnet when it released in February, though didn't find it a particularly impressive upgrade and noted it seemed a tad overzealous -- introducing unnecessary complexity and being too verbose. The remaining lack of web search capabilities left it feeling behind the curve.

LLMs continue to be poor in HTML and CSS, with a huge amount of unnecessary complexity and massive accessibility flaws in their implementations. Claude in particular goes [way overboard with ARIA](https://www.w3.org/WAI/ARIA/apg/practices/read-me-first/#noariaisbetterthanbadaria).

In March I transitioned over to using Google's Gemini 2.5 models for everything besides coding, and they proved hugely superior in most regards except for 'personality'. Their swift response times and fantastic use of web content make them incredibly useful. Shortly after my switch to Gemini, I began informing it (and ChatGPT, when I occasionally use it) who I am, which [prompts it to pull in useful context](/micros/20250424-0345).

I tested GPT Image 1 via ChatGPT and found it very impressive, but I don't have a need for image generation and found that its images tended to have a certain undesirable property regardless of style and are tinted yellow despite my best attempts to avoid it.

I gave Cursor a go around this time, but it failed in all the same ways GitHub Copilot did and continues to.

In April I began using Gemini's writing editor Gem for getting feedback on my grammar and flaws. I disagree with many of its suggestions and find it often tries to neuter any character, but it does act like a fresh pair of eyes and points out structural/grammatical/spelling issues.

Towards the conclusion of April, [I began experimenting with the freshly released Qwen3](/micros/20250429-0321). It is the first model I've found that runs reasonably locally on my laptop and has output worth using compared to current flagships.

With the introduction of Claude Sonnet 4 in May, I moved from Claude 3.7 Sonnet. Sonnet 4 is far more capable than previous iterations and doesn't fall victim to the same needless introduction of unnecessary complexity that 3.7 did. I was also pleased with Opus 4, but haven't found Sonnet lacking enough to justify paying for it.

The long-rumoured and much-hyped GPT-5 made its debut in August. While technically impressive, I found it largely iterative and on the whole mediocre. It is difficult to get good coding results from it, and it feels incredibly corporate. I find myself using ChatGPT at this point for quick, casual queries. I still fail to trust that LLMs will not hallucinate, but they are very adept at doing advanced searches across the web, factoring in context and filtering for relevant material in a way that is not necessarily hard for humans but is time-consuming. I largely ignore their direct textual output beyond simple matters but find use in their valuable reading list of provided sources.

Gemini 2.5 Flash Image (Nano Banana) also launched in August. The quality of the image generation isn't entirely perfect, but I'm very impressed by its capability to maintain consistency across generations. I used it to generate vague concepts of a bathroom renovation by providing it with pictures of tiles, amenities, and colours I'd picked. The results were poor and inconsistent but gave a good enough visual representation of the proposal to be valuable in visualising the output.

In September with the release of Sonnet 4.5, I switched over. Not a major upgrade, but certainly a welcome one. Around the same time my usage of Gemini itself fell by the wayside. Not particularly due to any failings on Gemini's part, it just wasn't necessary to use it and ChatGPT for my general AI needs.

In November I created an [index of my favourite albums](/library/albums) and then asked Google Gemini to analyse the music I'd listed, as well as my comments on what I liked about each album, to provide me some suggestions. The output of this was some of the best and most tailored music suggestions I've ever received.

At some point GitHub started generating commit messages which are generally extremely poor and worse than useless. I'd be inclined to turn them off completely, but they are useful when doing bulk handling of PRs and mass menial data entry/tweaking.

In December I moved back to using Gemini as my primary flagship LLM with the release of Gemini 3 and turned to using ChatGPT as a fallback following many improvements to the issues present at GPT-5's launch. Gemini 3 Pro Image (Nano Banana Pro) proved very technically impressive, but I remain without much need for image generation.

Through 2025 the dedicated chat interface still remains the superior way to interact with AI tooling in much of my experience. I'm yet to really find generative AI implemented into an app or website in a way that is superior to the alternative. The only thing that pops to mind is Adobe's rather impressive [turntable functionality](https://arstechnica.com/ai/2024/10/adobe-shows-off-3d-rotation-tool-for-flat-drawings/).

## Specific Usage

The two tasks I use AI models for the most are writing and coding, but I'm conscious I use them for these tasks differently from most people I see discussing them.

### Writing

I love writing, and I _don't_ want an LLM to do my writing for me. However, I do appreciate it providing feedback like a human reviewer would. Things such as picking up on wordiness or less-than-ideal grammar are fantastic use cases.

I often write alone for long periods and get caught up in my own head, so having something to riff off is beneficial. Like most writers, I sometimes hit a bit of a block, so being able to get an LLM to give me a nudge to push me along is great for my productivity. It is accessible and will provide feedback that, while not necessarily always good, does usually inspire or trigger some thought.

It is valuable in this way more like a debug duck than an assistant. Not necessarily providing good analysis, but prompting the thought needed to overcome a hurdle. LLMs sometimes serve in more of an editor role. For instance, when struggling to rephrase a clunky sentence, asking an LLM for a few alternative phrasings often sparks the exact direction I need, though I don't use any of the suggestions directly.

The absolute most useful function of LLMs when writing is as a context-aware thesaurus, as I realised fairly early on. Thesauruses are great, but sometimes one finds oneself using words in more abstract or unique contexts where the typical equivalents don't quite fit.

LLMs are a last resort that I use to keep velocity when writing. A small local model is more than enough for this purpose and is beholden to far fewer of the qualms I have with large offerings. It is a nudge, not a shove, and improves my work rather than replacing it.

### Coding

I will happily get AI models to generate large portions of code, but any non-vibe-coded AI-generated code I commit must be at the quality of code I would write myself and be checked along the way. Code being AI-generated is not itself an excuse for it being bad, and vigilant oversight is required.

When I use AI to generate code, I do it separate from my editor. Every experience I have had with in-editor AI has been poor unless I give it complete control, which I dislike doing for what I hope are obvious reasons. AI is a tool, not a replacement, so leaving it to do things on its own usually goes awry.

Inline suggestions are the most egregious of all the ways AI tries to help me in-editor. It gets directly underfoot and in my way to the extent it can. Suggestions are worse than what can be sourced from my LSP or elsewhere in my buffer and are frequently so wrong they're distracting.

Instead, I'll always opt for an external interface where I supply the relevant code and allow it to be handled as I wish, and this works extremely smoothly. This is also often more cost-effective given available free plans for flagship models. I'm very careful with my usage and ensure that I understand and am capable of everything that is output.

It is also incredibly useful for creating small, throwaway tools as part of the development process, as [I've discussed](/posts/build-use-and-improve-tools).
